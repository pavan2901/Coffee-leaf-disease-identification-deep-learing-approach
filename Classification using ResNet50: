import keras
import keras.backend as K
from keras.models import Model
from keras.layers.core import
Dense,Dropout,Activation,Flatten,Lambda

from keras.layers import Input, Dense, Conv2D, Conv3D,
DepthwiseConv2D, SeparableConv2D, Conv3DTranspose
from keras.layers import Flatten, MaxPool2D, AvgPool2D,
GlobalAvgPool2D, UpSampling2D, BatchNormalization
from keras.layers import Concatenate, Add, Dropout, ReLU,
Lambda, Activation
from keras.layers import LeakyReLU
from tensorflow.keras.layers import
Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalizati
on
from tensorflow.keras.layers import
Flatten,MaxPooling2D,Dropout,Input
from tensorflow.keras.applications.densenet import
preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import
ImageDataGenerator,img_to_array
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint,
ReduceLROnPlateau
from keras.preprocessing.image import ImageDataGenerator
from keras.applications import DenseNet121
from keras.models import Sequential, load_model
from keras.layers import Conv2D
from keras.layers import Activation, Dropout, Flatten,
Dense
from keras.callbacks import EarlyStopping,
ReduceLROnPlateau, ModelCheckpoint, Callback
from keras import regularizers
from keras import backend as K
import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sn
import pandas as pd
import pickle
import csv
from sklearn.metrics import confusion_matrix,
classification_report
import tensorflow as tf
from PIL import Image

import os
import tensorflow 
import pandas as pd
import numpy as np
import os
import keras
import random
import cv2
import math
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings(&quot;ignore&quot;)
from tensorflow.keras.applications.resnet50 import ResNet50
base_model = ResNet50(weights= None, include_top=False,
input_shape= (224,224,3))
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.7)(x)
predictions = Dense(5, activation= &#39;softmax&#39;)(x)
model = Model(inputs = base_model.input, outputs =
predictions)
model.summary()
model.compile(
optimizer = tf.keras.optimizers.Adam(learning_rate =
0.0001),
loss = tf.keras.losses.categorical_crossentropy,
metrics = [&#39;accuracy&#39;])
model.summary()

train_image_generator = ImageDataGenerator(



    rotation_range=25, width_shift_range=0.1,
    height_shift_range=0.1, shear_range=0.2,  
    horizontal_flip=True, 
    fill_mode=&quot;nearest&quot;,
    rescale = 1.0/255)
test_image_generator = ImageDataGenerator(
    rescale = 1.0/255)
val_image_generator = ImageDataGenerator(
    rescale = 1.0/255)
DATASET_DIR = &#39;/content/drive/MyDrive/symptom/&#39;
train_path             =
&quot;/content/drive/MyDrive/symptom/train&quot;
test_path              =
&quot;/content/drive/MyDrive/symptom/test&quot;
training_iterator=[]
training_iterator =
train_image_generator.flow_from_directory(&#39;/content/drive/M
yDrive/symptom/train&#39;,
target_size = (224, 224),
batch_size = 16)
test_iterator =
test_image_generator.flow_from_directory(&#39;/content/drive/My
Drive/symptom/test&#39;,
target_size = (224, 224),
batch_size = 16)
hist = model.fit(training_iterator,batch_size=16,
          epochs=20,verbose=1,shuffle=True,validation_data=tes
t_iterator)
train_image_generator = ImageDataGenerator(
    rotation_range=25, width_shift_range=0.1,
    height_shift_range=0.1, shear_range=0.2,  
    horizontal_flip=True, 
    fill_mode=&quot;nearest&quot;,
    rescale = 1.0/255)
test_image_generator = ImageDataGenerator(
    rescale = 1.0/255)
val_image_generator = ImageDataGenerator(
    rescale = 1.0/255)
val_iterator =
val_image_generator.flow_from_directory(&#39;/content/drive/MyD
rive/symptom/val&#39;,
target_size = (224, 224),
batch_size = 16)
import cv2

path_to_dataset =
os.listdir(&#39;/content/drive/MyDrive/symptom/train&#39;)
path = &#39;/content/drive/MyDrive/symptom/train&#39;
image_size=224
images = []
labels = []
for i in path_to_dataset:
  data_path = path+&#39;/&#39; + str(i)
  filename = [i for i in os.listdir(data_path)]
  for f in filename:
    image = cv2.imread(data_path+&#39;/&#39;+f)
    image = cv2.resize(image, (image_size,image_size))
    images.append(image)
    labels.append(i)
images = np.array(images)
images.shape
rows = []
for item in path_to_dataset:
  all_items =
os.listdir(&#39;/content/drive/MyDrive/symptom/train&#39;+&#39;/&#39;+item)
  for inner in all_items:
    rows.append((item,str(&#39;/content/drive/MyDrive/symptom/trai
n&#39;+&#39;/&#39;+item)+&#39;/&#39;+inner))
leaf_df = pd.DataFrame(data=rows, columns =
[&#39;dis_type&#39;,&#39;image&#39;])
print(leaf_df.tail())
from sklearn.preprocessing import LabelEncoder,
OneHotEncoder
y_name = leaf_df[&#39;dis_type&#39;].values
y = leaf_df[&#39;dis_type&#39;].values
y_label = LabelEncoder ()
y = y_label.fit_transform (y)
y.shape 
y = y.reshape(-1,1)
onehot = OneHotEncoder(sparse=True)
Y = onehot.fit_transform(y)
Y.shape
import cv2
path_to_dataset =
os.listdir(&#39;/content/drive/MyDrive/symptom/test&#39;)

path = &#39;/content/drive/MyDrive/symptom/test&#39;
image_size=224
testimages = []
labels = []
for i in path_to_dataset:
  data_path = path+&#39;/&#39; + str(i)
  filename = [i for i in os.listdir(data_path)]
  for f in filename:
    image = cv2.imread(data_path+&#39;/&#39;+f)
    image = cv2.resize(image, (image_size,image_size))
    testimages.append(image)
    labels.append(i)
testimages = np.array(testimages)
testimages.shape
rows = []
for item in path_to_dataset:
  all_items =
os.listdir(&#39;/content/drive/MyDrive/symptom/test&#39;+&#39;/&#39;+item)
  for inner in all_items:
    rows.append((item,str(&#39;/content/drive/MyDrive/symptom/test
&#39;+&#39;/&#39;+item)+&#39;/&#39;+inner))
leaf_df = pd.DataFrame(data=rows, columns =
[&#39;dis_type&#39;,&#39;image&#39;])
print(leaf_df.tail())
from sklearn.preprocessing import LabelEncoder,
OneHotEncoder
y1 = leaf_df[&#39;dis_type&#39;].values
y_label = LabelEncoder ()
y1 = y_label.fit_transform (y1)
y1.shape 
y1 = y1.reshape(-1,1)
onehot = OneHotEncoder(sparse=True)
Y1 = onehot.fit_transform(y1)
Y1.shape
from sklearn.datasets import make_blobs
import numpy as np
from sklearn.model_selection import train_test_split
X = np.array(images)
X1 = np.array(testimages)

x_train = X
y_train = Y
x_test = X1
y_test = Y1
x_test1 = x_test/255.0
Ypred = model.predict(x_test1)
Ypred = np.argmax(Ypred, axis=1)
print(Ypred)
Ytrue = np.argmax(y_test, axis=1)
print(Ytrue)
cm = confusion_matrix(Ytrue, Ypred)
plt.figure(figsize=(12, 12))
ax = sns.heatmap(cm, cmap=&quot;rocket_r&quot;,
fmt=&quot;.01f&quot;,annot_kws={&#39;size&#39;:16}, annot=True, square=True,)
ax.set_ylabel(&#39;Actual&#39;, fontsize=20)
ax.set_xlabel(&#39;Predicted&#39;, fontsize=20)
from sklearn.metrics import precision_score
print(&#39;Precision: %.3f&#39; % precision_score(Ytrue,
Ypred,average=&quot;micro&quot;))
from sklearn.metrics import recall_score
recall = recall_score(Ytrue, Ypred, average=&#39;micro&#39;)
print(recall)
from sklearn.metrics import mean_squared_error
plt.figure(0)
plt.plot(hist.history[&#39;accuracy&#39;],&#39;r&#39;)
plt.plot(hist.history[&#39;val_accuracy&#39;],&#39;g&#39;)
plt.xticks(np.arange(0, 20, 1.0))
plt.rcParams[&#39;figure.figsize&#39;] = (8, 6)
plt.xlabel(&quot;Num of Epochs&quot;)
plt.ylabel(&quot;Accuracy&quot;)
plt.title(&quot;Training Accuracy vs Validation Accuracy&quot;)
plt.legend([&#39;train&#39;,&#39;validation&#39;])
 
plt.figure(1)
plt.plot(hist.history[&#39;loss&#39;],&#39;r&#39;)
plt.plot(hist.history[&#39;val_loss&#39;],&#39;g&#39;)
plt.xticks(np.arange(0, 20, 1.0))
plt.rcParams[&#39;figure.figsize&#39;] = (8, 6)
plt.xlabel(&quot;Num of Epochs&quot;)
plt.ylabel(&quot;Loss&quot;)
plt.title(&quot;Training Loss vs Validation Loss&quot;)
plt.legend([&#39;train&#39;,&#39;validation&#39;])
plt.figure(2)
plt.plot(hsit.history[&#39;mean_squared_error&#39;],&#39;r&#39;)
plt.plot(hist.history[&#39;val_mean_squared_error&#39;],&#39;g&#39;)
plt.xticks(np.arange(0, 10, 1.0))
plt.rcParams[&#39;figure.figsize&#39;] = (8, 6)
plt.xlabel(&quot;Num of Epochs&quot;)


plt.ylabel(&quot;MSE&quot;)
plt.title(&quot;Training Loss vs Validation Loss&quot;)
plt.legend([&#39;train&#39;,&#39;validation&#39;])
 
plt.show()
