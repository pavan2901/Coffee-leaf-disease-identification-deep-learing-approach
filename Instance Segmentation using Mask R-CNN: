from google.colab import drive
drive.mount(&#39;/content/drive&#39;)
&quot;&quot;&quot;Importing the necessary modules&quot;&quot;&quot;
import os
import sys
import matplotlib.pyplot as plt
import numpy as np
import cv2
import torchvision
import PIL as Image
import random
import detectron2
from detectron2.utils.logger import setup_logger
setup_logger()
from detectron2.engine import DefaultPredictor,
DefaultTrainer
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer,
ColorMode
from detectron2.data import MetadataCatalog,
DatasetCatalog, build_detection_test_loader
from detectron2.data.datasets import
register_coco_instances
from detectron2.evaluation import COCOEvaluator,
inference_on_dataset
from detectron2 import model_zoo
from google.colab.patches import cv2_imshow
&quot;&quot;&quot;Declaring some functions for the execution.&quot;&quot;&quot;
def cfg(training_data, testing_data, img_per_batch,
max_iterations):
  cfg = get_cfg()
  cfg.merge_from_file(model_zoo.get_config_file(&quot;COCO-
InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;))
  cfg.DATASETS.TRAIN = (training_data,)
  cfg.DATASETS.TEST = (testing_data, )
  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(&quot;COCO-
InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;)  
  cfg.SOLVER.IMS_PER_BATCH = img_per_batch
  cfg.SOLVER.MAX_ITER = max_iterations
  cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512
  cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2
  cfg.SOLVER.BASE_LR = 0.005
  cfg.DATALOADER.NUM_WORKERS = 2
  
  return cfg
def training(cfg):

15

  os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)
  trainer = DefaultTrainer(cfg)
  trainer.resume_or_load(resume = False)
  trainer.train()
def evaluating_coco(predictor, test_data, cfg):
  evaluator = COCOEvaluator(test_data, False, output_dir =
&quot;./output&quot;)
  value_loader = build_detection_test_loader(cfg,
test_data)
  inference_on_dataset(predictor.model, value_loader,
evaluator)
&quot;&quot;&quot;Initializing the test and train datasets and the
annotations.&quot;&quot;&quot;
training_json_path = &quot;/content/drive/MyDrive/bracot-
data/train/train_annotation_coco.json&quot;
testing_json_path = &quot;/content/drive/MyDrive/bracot-
data/test/test_annotation_coco.json&quot;
train_img_root_folder = &quot;/content/drive/MyDrive/bracot-
data/train/&quot;
test_img_root_folder = &quot;/content/drive/MyDrive/bracot-
data/test/&quot;
training_data = &quot;train_data&quot;
testing_data = &quot;test_data&quot;
&quot;&quot;&quot;Registering the datasets in the COCO format &quot;&quot;&quot;
register_coco_instances(name = training_data, metadata =
{}, json_file = training_json_path, image_root =
train_img_root_folder)
register_coco_instances(name = testing_data, metadata = {},
json_file = testing_json_path, image_root =
test_img_root_folder)
config_params = cfg(training_data = training_data,
testing_data = testing_data, img_per_batch = 1,
max_iterations = 2000)
&quot;&quot;&quot;Training the model to the configurations.&quot;&quot;&quot;
training(cfg = config_params)
&quot;&quot;&quot;Assigning weights from the trained model.&quot;&quot;&quot;
weights= &quot;/content/output/model_final.pth&quot;
config_params.MODEL.WEIGHTS =
os.path.join(config_params.OUTPUT_DIR, weights)
config_params.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7
predictor = DefaultPredictor(config_params)

16
&quot;&quot;&quot;Evaluating the trained model&quot;&quot;&quot;
evaluating_coco(predictor = predictor, test_data =
testing_data, cfg = config_params)
&quot;&quot;&quot;Testing the model with one image from test data&quot;&quot;&quot;
image_path = &quot;/content/drive/MyDrive/bracot-
data/test/20190831_163123.jpg&quot;
image = cv2.imread(image_path)
outputs = predictor(image)
v = Visualizer(image[:, :, ::-1], 
               metadata =
MetadataCatalog.get(config_params.DATASETS.TRAIN[0]), 
               scale = 1, instance_mode =
ColorMode.IMAGE_BW 
               )
v =
v.draw_instance_predictions(outputs[&quot;instances&quot;].to(&quot;cpu&quot;))
print(v)
cv2_imshow(v.get_image()[:, :, ::-1])
&quot;&quot;&quot;Functions for isolating individual leaves from the
background&quot;&quot;&quot;
def create_fig (img, mask):
    temp = img.copy()
    r, c, _ = img.shape
    for i in range (0, r):
        for j in range (0, c):
            if mask[i][j] &lt; 0.1:
                temp[i][j][0] = 255 
                temp[i][j][1] = 255 
                temp[i][j][2] = 255 
    return temp
def create_outputs(predictor, img_path):
        image = cv2.imread(img_path)
        outputs = predictor(image)
        v = Visualizer(image[:, :, ::-1],
                    scale=1, 
                    instance_mode=ColorMode.IMAGE_BW
        )
        v =
v.draw_instance_predictions(outputs[&quot;instances&quot;].to(&quot;cpu&quot;))
        if not
os.path.exists(&#39;/content/drive/MyDrive/outputs/&#39;):
            os.makedirs(&#39;/content/drive/MyDrive/outputs/instan
ce_seg_result&#39;)
        cv2.imwrite(f&#39;/content/drive/MyDrive/outputs/instance_
seg_result/instanceseg.png&#39;, v.get_image()[:, :, ::-1])

17

        masks =
outputs[&quot;instances&quot;].to(&quot;cpu&quot;).pred_masks.numpy()
        j = 0
        for mask in masks:
            temp = create_fig(image, mask)
            cv2.imwrite(f&quot;/content/drive/MyDrive/outputs/insta
nce_seg_result/{j}.jpg&quot;, temp)
            j += 1
create_outputs(predictor=predictor, img_path=image_path)
