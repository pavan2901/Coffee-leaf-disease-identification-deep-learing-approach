from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D,
UpSampling2D, concatenate, Conv2DTranspose,
BatchNormalization, Dropout, Lambda
def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):
    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    s = inputs
    c1 = Conv2D(16, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(s)
    c1 = Dropout(0.1)(c1)
    c1 = Conv2D(16, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c1)
    p1 = MaxPooling2D((2, 2))(c1)
    
    c2 = Conv2D(32, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c2)
    p2 = MaxPooling2D((2, 2))(c2)
     
    c3 = Conv2D(64, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c3)
    p3 = MaxPooling2D((2, 2))(c3)
     
    c4 = Conv2D(128, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c4)
    p4 = MaxPooling2D(pool_size=(2, 2))(c4)
     



    c5 = Conv2D(256, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv2D(256, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c5)
    
    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2),
padding=&#39;same&#39;)(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c6)
     
    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2),
padding=&#39;same&#39;)(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c7)
     
    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2),
padding=&#39;same&#39;)(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(u8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv2D(32, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c8)
     
    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2),
padding=&#39;same&#39;)(c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(u9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv2D(16, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c9)
     
    outputs = Conv2D(1, (1, 1), activation=&#39;sigmoid&#39;)(c9)
     
    model = Model(inputs=[inputs], outputs=[outputs])
    model.compile(optimizer=&#39;adam&#39;,
loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
    model.summary()
    
    return model
from tensorflow import keras


from tensorflow.keras import layers
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt
import numpy as np
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D,
UpSampling2D, concatenate, Conv2DTranspose,
BatchNormalization, Dropout, Lambda
def multi_unet_model(n_classes=3, IMG_HEIGHT=256,
IMG_WIDTH=256, IMG_CHANNELS=3):
    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    s = inputs
    c1 = Conv2D(16, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(s)
    c1 = Dropout(0.1)(c1)
    c1 = Conv2D(16, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c1)
    p1 = MaxPooling2D((2, 2))(c1)
    
    c2 = Conv2D(32, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c2)
    p2 = MaxPooling2D((2, 2))(c2)
     
    c3 = Conv2D(64, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c3)
    p3 = MaxPooling2D((2, 2))(c3)
     
    c4 = Conv2D(128, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c4)
    p4 = MaxPooling2D(pool_size=(2, 2))(c4)
     
    c5 = Conv2D(256, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv2D(256, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c5)
    
    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2),
padding=&#39;same&#39;)(c5)
    u6 = concatenate([u6, c4])



    c6 = Conv2D(128, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c6)
     
    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2),
padding=&#39;same&#39;)(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c7)
     
    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2),
padding=&#39;same&#39;)(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(u8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv2D(32, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c8)
     
    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2),
padding=&#39;same&#39;)(c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(u9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv2D(16, (3, 3), activation=&#39;relu&#39;,
kernel_initializer=&#39;he_normal&#39;, padding=&#39;same&#39;)(c9)
     
    outputs = Conv2D(n_classes, (1, 1),
activation=&#39;softmax&#39;)(c9)
     
    model = Model(inputs=[inputs], outputs=[outputs])
    
    model.compile(optimizer=&#39;adam&#39;,
loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
    
    model.summary()
    
    return model

from keras.utils.np_utils import normalize
from tensorflow.keras.utils import normalize



import keras
import tensorflow as tf
import segmentation_models as sm
import os
from glob import glob
import cv2
import numpy as np
from matplotlib import pyplot as plt
from keras.metrics import MeanIoU
SIZE_X = 256 
SIZE_Y = 256
n_classes=3
train_images = []
train_images=[]
for directory_path in
glob(&quot;/content/drive/MyDrive/dataset/images/train/&quot;):
    for img_path in glob(os.path.join(directory_path,
&quot;*.jpg&quot;)):
        img = cv2.imread(img_path, 0)       
        img = cv2.resize(img, (SIZE_Y, SIZE_X))
        train_images.append(img)
       
train_images = np.array(train_images)
print(train_images)
train_masks = [] 
for directory_path in
glob(&quot;/content/drive/MyDrive/dataset/annotations/train/&quot;):
    print(glob(os.path.join(directory_path, &quot;*.png&quot;)))
    for mask_path in glob(os.path.join(directory_path,
&quot;*.png&quot;)):
        mask = cv2.imread(mask_path, 0)       
        mask = cv2.resize(mask, (SIZE_Y, SIZE_X),
interpolation = cv2.INTER_NEAREST) 
        train_masks.append(mask)
train_masks = np.array(train_masks)
print(train_masks)
from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
n,h,w = train_masks.shape
train_masks_reshaped = train_masks.reshape(-1,1)
train_masks_reshaped_encoded =
labelencoder.fit_transform(train_masks_reshaped)
train_masks_encoded_original_shape =
train_masks_reshaped_encoded.reshape(n, h, w)
np.unique(train_masks_encoded_original_shape)


from google.colab import drive
drive.mount(&#39;/content/drive&#39;)
from keras.utils import normalize
train_images = np.expand_dims(train_images, axis=3)
train_images = normalize(train_images, axis=1)
print(train_images)
train_masks_input =
np.expand_dims(train_masks_encoded_original_shape, axis=3)
test_images=[]
for directory_path in
glob(&quot;/content/drive/MyDrive/dataset/images/test/&quot;):
    for img_path in glob(os.path.join(directory_path,
&quot;*.jpg&quot;)):
        img = cv2.imread(img_path, 0)       
        img = cv2.resize(img, (SIZE_Y, SIZE_X))
        test_images.append(img)
             
test_images = np.array(test_images)
test_masks = [] 
for directory_path in
glob(&quot;/content/drive/MyDrive/dataset/annotations/test/&quot;):
    for mask_path in glob(os.path.join(directory_path,
&quot;*.png&quot;)):
        mask = cv2.imread(mask_path, 0)       
        mask = cv2.resize(mask, (SIZE_Y, SIZE_X),
interpolation = cv2.INTER_NEAREST)  
        test_masks.append(mask)
test_masks = np.array(test_masks)
test_images = np.expand_dims(test_images, axis=3)
test_images = normalize(test_images, axis=1)
from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
n,h,w = test_masks.shape
print(n,h,w)
test_masks_reshaped = test_masks.reshape(-1,1)
test_masks_reshaped_encoded =
labelencoder.fit_transform(test_masks_reshaped)
test_masks_encoded_original_shape =
test_masks_reshaped_encoded.reshape(n, h, w)
np.unique(test_masks_encoded_original_shape)



test_masks_input =
np.expand_dims(test_masks_encoded_original_shape, axis=3)
X_train = train_images
y_train = train_masks_input
X_test = test_images
y_test = test_masks_input
from keras.utils import to_categorical
train_masks_cat = to_categorical(y_train,
num_classes=n_classes)
y_train_cat = train_masks_cat.reshape((y_train.shape[0],
y_train.shape[1], y_train.shape[2], n_classes))
test_masks_cat = to_categorical(y_test,
num_classes=n_classes)
y_test_cat = test_masks_cat.reshape((y_test.shape[0],
y_test.shape[1], y_test.shape[2], n_classes))
X_train = train_images
y_train = train_masks_input
X_test = test_images
y_test = test_masks_input
from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight(
                                        class_weight =
&quot;balanced&quot;,
                                        classes =
np.unique(train_masks_reshaped_encoded),
                                        y =
train_masks_reshaped_encoded                               
                     
                                    )
print(&quot;Class weights are...:&quot;, class_weights)
IMG_HEIGHT = X_train.shape[1]
IMG_WIDTH  = X_train.shape[2]
IMG_CHANNELS = X_train.shape[3]
def get_model():
    return multi_unet_model(n_classes=n_classes,
IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH,
IMG_CHANNELS=IMG_CHANNELS)
model = get_model()
model.compile(optimizer=&#39;adam&#39;,
loss=&#39;categorical_crossentropy&#39;, metrics=[&#39;accuracy&#39;])
model.summary()
history = model.fit(X_train, y_train_cat, 

                    batch_size = 16, 
                    verbose=1, 
                    epochs=10, 
                    validation_data=(X_test, y_test_cat), 
                    shuffle=False)
_, acc = model.evaluate(X_test, y_test_cat)
print(&quot;Accuracy is = &quot;, (acc * 100.0), &quot;%&quot;)
loss = history.history[&#39;loss&#39;]
val_loss = history.history[&#39;val_loss&#39;]
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, &#39;y&#39;, label=&#39;Training loss&#39;)
plt.plot(epochs, val_loss, &#39;r&#39;, label=&#39;Validation loss&#39;)
plt.title(&#39;Training and validation loss&#39;)
plt.xlabel(&#39;Epochs&#39;)
plt.ylabel(&#39;Loss&#39;)
plt.legend()
plt.show()
acc = history.history[&#39;accuracy&#39;]
val_acc = history.history[&#39;val_accuracy&#39;]
plt.plot(epochs, acc, &#39;y&#39;, label=&#39;Training Accuracy&#39;)
plt.plot(epochs, val_acc, &#39;r&#39;, label=&#39;Validation Accuracy&#39;)
plt.title(&#39;Training and validation Accuracy&#39;)
plt.xlabel(&#39;Epochs&#39;)
plt.ylabel(&#39;Accuracy&#39;)
plt.legend()
plt.show()
y_pred=model.predict(X_test)
y_pred_argmax=np.argmax(y_pred, axis=3)
from keras.metrics import MeanIoU
n_classes = 3
IOU_keras = MeanIoU(num_classes=n_classes)  
IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)
print(&quot;Mean IoU =&quot;, IOU_keras.result().numpy())
values =
np.array(IOU_keras.get_weights()).reshape(n_classes,
n_classes)
print(values)
class1_IoU = values[0,0]/(values[0,0] + values[0,1] +
values[0,2] + values[1,0]+ values[2,0])
class2_IoU = values[1,1]/(values[1,1] + values[1,0] +
values[1,2] + values[0,1]+ values[2,1])
class3_IoU = values[2,2]/(values[2,2] + values[2,0] +
values[2,1] + values[0,2]+ values[1,2])


print(&quot;IoU for class1 is: &quot;, class1_IoU)
print(&quot;IoU for class2 is: &quot;, class2_IoU)
print(&quot;IoU for class3 is: &quot;, class3_IoU)
plt.imshow(train_images[0, :,:,0], cmap=&#39;gray&#39;)
plt.imshow(train_masks[0], cmap=&#39;gray&#39;)
import random
test_img_number = random.randint(0, len(X_test))
test_image =
cv2.imread(&quot;/content/drive/MyDrive/dataset/images/test/349.
jpg&quot;)
test_mask =
cv2.imread(&quot;/content/drive/MyDrive/dataset/annotations/test
/349_mask.png&quot;)
test_mask = cv2.resize(test_mask, (SIZE_Y, SIZE_X),
interpolation = cv2.INTER_NEAREST)
test_image = cv2.resize(test_image, (SIZE_Y, SIZE_X))
test_image = np.array(test_image)
test_mask = np.array(test_mask)
test_img = test_image
ground_truth=test_mask
test_img_norm=test_img[:,:,0][:,:,None]
test_img_input=np.expand_dims(test_img_norm, 0)
prediction = (model.predict(test_img_input))
predicted_img=np.argmax(prediction, axis=3)[0]

plt.figure(figsize=(12, 8))
plt.subplot(231)
plt.title(&#39;Testing Image&#39;)
plt.imshow(test_img, cmap=&#39;gray&#39;)
plt.subplot(232)
plt.title(&#39;Testing Label&#39;)
plt.imshow(ground_truth[:,:], cmap=&#39;jet&#39;)
plt.subplot(233)
plt.title(&#39;Prediction on test image&#39;)
plt.imshow(predicted_img[:,:], cmap=&#39;jet&#39;)
plt.show()
import random
test_img_number = random.randint(0, len(X_test))
test_img = X_train[test_img_number]
ground_truth=y_test_cat[test_img_number]
test_img_norm=test_img[:,:,0][:,:,None]
test_img_input=np.expand_dims(test_img_norm, 0)
prediction = (model.predict(test_img_input))
predicted_img=np.argmax(prediction, axis=3)[0,:,:]
print(test_img_number)
plt.figure(figsize=(12, 8))


plt.subplot(231)
plt.title(&#39;Testing Image&#39;)
plt.imshow(test_img[:,:,0], cmap=&#39;gray&#39;)
plt.subplot(232)
plt.title(&#39;Prediction on test image&#39;)
plt.imshow(ground_truth[:,:,0], cmap=&#39;jet&#39;)
plt.subplot(233)
plt.title(&#39;Prediction on test image&#39;)
plt.imshow(predicted_img, cmap=&#39;jet&#39;)
plt.show()
